package splunk

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/hashicorp/terraform-plugin-sdk/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/helper/validation"
	"net/http"
	"regexp"
	"terraform-provider-splunk/client/models"
)

func outputsTCPGroup() *schema.Resource {
	return &schema.Resource{
		Schema: map[string]*schema.Schema{
			"compressed": {
				Type:     schema.TypeBool,
				Optional: true,
				Computed: true,
				Description: "If true, forwarder sends compressed data." +
					"If set to true, the receiver port must also have compression turned on. ",
			},
			"disabled": {
				Type:        schema.TypeBool,
				Optional:    true,
				Computed:    true,
				Description: "If true, disables the group.",
			},
			"drop_events_on_queue_full": {
				Type:     schema.TypeInt,
				Optional: true,
				Computed: true,
				Description: "If set to a positive number, wait the specified number of seconds before throwing out all new events until the output queue has space. " +
					"Defaults to -1 (do not drop events)." +
					"CAUTION: Do not set this value to a positive integer if you are monitoring files." +
					"Setting this to -1 or 0 causes the output queue to block when it gets full, which causes further blocking up the processing chain. " +
					"If any target group queue is blocked, no more data reaches any other target group." +
					"Using auto load-balancing is the best way to minimize this condition, because, in that case," +
					" multiple receivers must be down (or jammed up) before queue blocking can occur. ",
			},
			"heartbeat_frequency": {
				Type:     schema.TypeInt,
				Optional: true,
				Computed: true,
				Description: " 	How often (in seconds) to send a heartbeat packet to the receiving server." +
					"Heartbeats are only sent if sendCookedData=true. Defaults to 30 seconds. ",
			},
			"max_queue_size": {
				Type:         schema.TypeString,
				Optional:     true,
				Computed:     true,
				ValidateFunc: validation.StringMatch(validMaxQueueSize, "valid values: integer[KB|MB|GB]"),
				Description: "Specify an integer or integer[KB|MB|GB]." +
					"Sets the maximum size of the forwarder output queue. " +
					"It also sets the maximum size of the wait queue to 3x this value, if you have enabled indexer acknowledgment (useACK=true)." +
					"Although the wait queue and the output queues are both configured by this attribute, they are separate queues. " +
					"The setting determines the maximum size of the queue in-memory (RAM) buffer." +
					"For heavy forwarders sending parsed data, maxQueueSize is the maximum number of events. " +
					"Since events are typically much shorter than data blocks, the memory consumed by the queue " +
					"on a parsing forwarder is likely to be much smaller than on a non-parsing forwarder, if you use this version of the setting." +
					"If specified as a lone integer (for example, maxQueueSize=100), " +
					"maxQueueSize indicates the maximum number of queued events (for parsed data) or blocks of data (for unparsed data). " +
					"A block of data is approximately 64KB. For non-parsing forwarders, such as universal forwarders, " +
					"that send unparsed data, maxQueueSize is the maximum number of data blocks." +
					"If specified as an integer followed by KB, MB, or GB (for example, maxQueueSize=100MB), " +
					"maxQueueSize indicates the maximum RAM allocated to the queue buffer. " +
					"Defaults to 500KB (which means a maximum size of 500KB for the output queue and 1500KB for the wait queue, if any). ",
			},
			"method": {
				Type:         schema.TypeString,
				Optional:     true,
				Computed:     true,
				ValidateFunc: validation.StringInSlice([]string{"tcpout", "syslog"}, false),
				Description:  "Valid values: (tcpout | syslog). Specifies the type of output processor. ",
			},
			"name": {
				Type:        schema.TypeString,
				Required:    true,
				ForceNew:    true,
				Description: "The name of the group of receivers.",
			},
			"send_cooked_data": {
				Type:     schema.TypeBool,
				Optional: true,
				Computed: true,
				Description: "If true, events are cooked (processed by Splunk software). If false, events are raw and untouched prior to sending. " +
					"Defaults to true. Set to false if you are sending to a third-party system. ",
			},
			"servers": {
				Type:     schema.TypeList,
				Required: true,
				Elem: &schema.Schema{
					Type:         schema.TypeString,
					ValidateFunc: validation.StringMatch(validTCPServer, "<host>:<port> of the Splunk receiver"),
				},
				Description: "Comma-separated list of servers to include in the group.",
			},
			"token": {
				Type:        schema.TypeString,
				Optional:    true,
				Computed:    true,
				Description: "Token value generated by the indexer after configuration.",
			},
			"acl": aclSchema(),
		},
		Read:   outputsTCPGroupRead,
		Create: outputsTCPGroupCreate,
		Update: outputsTCPGroupUpdate,
		Delete: outputsTCPGroupDelete,
		Importer: &schema.ResourceImporter{
			State: schema.ImportStatePassthrough,
		},
	}
}

// Functions
func outputsTCPGroupCreate(d *schema.ResourceData, meta interface{}) error {
	provider := meta.(*SplunkProvider)
	name := d.Get("name").(string)
	outputsTCPGroupConfig := getOutputsTCPGroupConfig(d)
	aclObject := &models.ACLObject{}
	if r, ok := d.GetOk("acl"); ok {
		aclObject = getACLConfig(r.([]interface{}))
	} else {
		aclObject.Owner = "nobody"
		aclObject.App = "search"
	}

	err := (*provider.Client).CreateTCPGroupOutput(name, aclObject.Owner, aclObject.App, outputsTCPGroupConfig)
	if err != nil {
		return err
	}

	if _, ok := d.GetOk("acl"); ok {
		err = (*provider.Client).UpdateAcl(aclObject.Owner, aclObject.App, d.Id(), aclObject, "data", "outputs", "tcp", "group")
		if err != nil {
			return err
		}
	}

	d.SetId(name)
	return outputsTCPGroupRead(d, meta)
}

func outputsTCPGroupRead(d *schema.ResourceData, meta interface{}) error {
	provider := meta.(*SplunkProvider)
	// We first get list of outputs to get owner and app name for the specific input
	resp, err := (*provider.Client).ReadTCPGroupOutputs()
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	entry, err := getOutputsTCPGroupConfigByName(d.Id(), resp)
	if err != nil {
		return err
	}

	if entry == nil {
		return errors.New(fmt.Sprintf("Unable to find resource: %v", d.Id()))
	}

	// Now we read the input configuration with proper owner and app
	resp, err = (*provider.Client).ReadTCPGroupOutput(entry.Name, entry.ACL.Owner, entry.ACL.App)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	entry, err = getOutputsTCPGroupConfigByName(d.Id(), resp)
	if err != nil {
		return err
	}

	if entry == nil {
		return errors.New(fmt.Sprintf("Unable to find resource: %v", d.Id()))
	}

	if err = d.Set("name", d.Id()); err != nil {
		return err
	}

	if err = d.Set("compressed", entry.Content.Compressed); err != nil {
		return err
	}

	if err = d.Set("method", entry.Content.Method); err != nil {
		return err
	}

	if err = d.Set("drop_events_on_queue_full", entry.Content.DropEventsOnQueueFull); err != nil {
		return err
	}

	if err = d.Set("heartbeat_frequency", entry.Content.HeartbeatFrequency); err != nil {
		return err
	}

	if err = d.Set("max_queue_size", entry.Content.MaxQueueSize); err != nil {
		return err
	}

	if err = d.Set("disabled", entry.Content.Disabled); err != nil {
		return err
	}

	if err = d.Set("send_cooked_data", entry.Content.SendCookedData); err != nil {
		return err
	}

	if err = d.Set("servers", entry.Content.Servers); err != nil {
		return err
	}

	if err = d.Set("token", entry.Content.Token); err != nil {
		return err
	}

	err = d.Set("acl", flattenACL(&entry.ACL))
	if err != nil {
		return err
	}

	return nil
}

func outputsTCPGroupUpdate(d *schema.ResourceData, meta interface{}) error {
	provider := meta.(*SplunkProvider)
	outputsTCPGroupConfig := getOutputsTCPGroupConfig(d)
	aclObject := getACLConfig(d.Get("acl").([]interface{}))
	err := (*provider.Client).UpdateTCPGroupOutput(d.Id(), aclObject.Owner, aclObject.App, outputsTCPGroupConfig)
	if err != nil {
		return err
	}

	//ACL update
	err = (*provider.Client).UpdateAcl(aclObject.Owner, aclObject.App, d.Id(), aclObject, "data", "outputs", "tcp", "group")
	if err != nil {
		return err
	}

	return outputsTCPGroupRead(d, meta)
}

func outputsTCPGroupDelete(d *schema.ResourceData, meta interface{}) error {
	provider := meta.(*SplunkProvider)
	aclObject := getACLConfig(d.Get("acl").([]interface{}))
	resp, err := (*provider.Client).DeleteTCPGroupOutput(d.Id(), aclObject.Owner, aclObject.App)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	switch resp.StatusCode {
	case 200, 201:
		return nil

	default:
		errorResponse := &models.OutputsTCPGroupResponse{}
		_ = json.NewDecoder(resp.Body).Decode(errorResponse)
		err := errors.New(errorResponse.Messages[0].Text)
		return err
	}
}

// Helpers
func getOutputsTCPGroupConfig(d *schema.ResourceData) (outputsTCPGroupObj *models.OutputsTCPGroupObject) {
	outputsTCPGroupObj = &models.OutputsTCPGroupObject{}
	outputsTCPGroupObj.Compressed = d.Get("compressed").(bool)
	outputsTCPGroupObj.Disabled = d.Get("disabled").(bool)
	outputsTCPGroupObj.DropEventsOnQueueFull = d.Get("drop_events_on_queue_full").(int)
	outputsTCPGroupObj.HeartbeatFrequency = d.Get("heartbeat_frequency").(int)
	outputsTCPGroupObj.MaxQueueSize = d.Get("max_queue_size").(string)
	outputsTCPGroupObj.Method = d.Get("method").(string)
	outputsTCPGroupObj.SendCookedData = d.Get("send_cooked_data").(bool)
	if val, ok := d.GetOk("servers"); ok {
		for _, v := range val.([]interface{}) {
			outputsTCPGroupObj.Servers = append(outputsTCPGroupObj.Servers, v.(string))
		}
	}
	outputsTCPGroupObj.Token = d.Get("token").(string)
	return
}

func getOutputsTCPGroupConfigByName(name string, httpResponse *http.Response) (entry *models.OutputsTCPGroupEntry, err error) {
	response := &models.OutputsTCPGroupResponse{}
	switch httpResponse.StatusCode {
	case 200, 201:
		err = json.NewDecoder(httpResponse.Body).Decode(&response)
		re := regexp.MustCompile(`(.*)`)
		for _, e := range response.Entry {
			if name == re.FindStringSubmatch(e.Name)[1] {
				return &e, nil
			}
		}

	default:
		_ = json.NewDecoder(httpResponse.Body).Decode(response)
		err := errors.New(response.Messages[0].Text)
		return entry, err
	}

	return entry, nil
}
